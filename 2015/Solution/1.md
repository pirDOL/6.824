## 1 worker failure
### 1.1 模拟故障
每个worker在完成n次RPC以后worker的RPC server线程退出：

* TestOneFailure：启动2个worker，其中一个worker执行10次RPC请求以后退出
* TestManyFailures：每秒启动2个worker，每个worker都是执行10次RPC请求以后退出

```golang
// mapreduce/worker.go
func RunWorker(MasterAddress string, me string,
    MapFunc func(string) *list.List,
    ReduceFunc func(string, *list.List) string, nRPC int) {

    ...
    // DON'T MODIFY CODE BELOW
    for wk.nRPC != 0 {
        conn, err := wk.l.Accept()
        if err == nil {
            wk.nRPC -= 1
            go rpcs.ServeConn(conn)
            wk.nJobs += 1
        } else {
            break
        }
    }
    ...
}

// mapreduce/test_test.go
func TestOneFailure(t *testing.T) {
    ...
    go RunWorker(mr.MasterAddress, port("worker"+strconv.Itoa(0)),
        MapFunc, ReduceFunc, 10)
}
```

**需要补充的故障场景：前提：master和worker之间的rpc使用tcp短连接**

1. worker接收到了master请求，但是执行过程中worker退出，master收不到结果，比如数据格式错误导致worker coredump。在代码层面表现为：`rpc.Dial`成功，但`rpc.Call`超时
2. worker向master返回了结果，其中表示任务执行结果的状态为失败，在代码层面表现为：worker向master返回的`DoJobReply.OK`为false

### 1.2 处理思路
#### 1.2.1 Master感知worker故障

* 应用层：`DoJobReply.OK`为false表示worker接收到了master的请求，并且任务执行的过程中出现了异常，worker把这个异常通过RPC返回给master，**当前并没有模拟这个故障**。
* RPC层：`call`返回false表示master和worker在RPC通信层面上出现故障，有两个分支：

    1. `rpc.Dial`：worker退出了，对应的socket不在监听状态，建立tcp连接失败
    1. `c.Call`：当前模拟的故障是worker处理n次RPC请求以后就退出，如果worker退出了，那么`Dial`就失败返回了，不会执行到`c.Call`
 
```golang
func call(srv string, rpcname string,
    args interface{}, reply interface{}) bool {
    c, errx := rpc.Dial("unix", srv)
    if errx != nil {
        return false
    }
    defer c.Close()

    err := c.Call(rpcname, args, reply)
    if err == nil {
        return true
    }

    fmt.Println(err)
    return false
}
```

#### 1.2.3 Master增加的数据结构

`failedJobNumber`：key为执行失败的jobNumber，value为`struct{}`，把map当作hashset使用，当job完成时能够以`O(1)`的时间通过jobNumber查找到是否为重试job。
```golang
failedJobNumber := make(map[int]struct{}, 0)
```

`DoJobContext`：在`DoJobReply`外层封装了JobNumber，调用RPC的goroutine通过channel传递给master，master判断如果是失败的job就重试。这里利用golang默认初始化为零值的特性，如果master和worker之间的RPC通信失败，`DoJobReply`实际上就没有被赋值，那么`DoJobReply.OK`就是初始化的零值false。换言之`DoJobReply.OK`为false，可能是RPC层面失败，也可能是应用层面失败，暂时不需要区分这两种失败。
```golang
type DoJobContext struct {
    DoJobReply
    JobNumber int
}
doJobContextCh := make(chan DoJobContext)
```

#### 1.2.3 Master任务分发和重试策略
核心是master的select事件处理

1. `mr.registerChannel`可读：新worker启动并向master发起注册。
    * 创建一个goroutine把worker的地址（2015年的worker地址是unix域socket名字）写入`mr.idleWorkerChannel`，如果不创建goroutine，因为`mr.idleWorkerChannel`也是master的select监听的，并且channel没有buffer，会导致select死锁（在一个case中写被另一个case读的channel）

1. `mr.idleWorkers`：有空闲worker可以分发job，空闲的worker来源有两个，一个是刚注册的，另一个是job执行完成的
    1. 如果所有job都执行成功，调用`mr.KillWorkers()`，master退出。所有job执行成功的判断条件：`(mr.nMap+mr.nReduce)个job都已经分发 && 没有正在执行的job && 没有失败等待重试的job`
    2. 优先分发执行失败待重试的job：随机从`failedJobNumber`中取一个jobNumber，取完以后要删除，否则如果此时再来一个空闲的worker，会重复分配这个已经重试但是没有执行完成的job
    3. 如果没有待重试的job则递增全局的jobNumber，继续分发下一个job。如果所有的job都已经分发（全局jobNumber >= mr.nMap+mr.nReduce），就continue，即不再向这个worker分发job。
    4. 构造RPC调用参数，创建一个goroutine调用RPC，将job执行结果通过`doJobContextCh`发回master，通过`call`的返回值判断是否回收worker，如果`call`返回false，说明这个worker已经退出了，那么不应该把它的地址写回`mr.idleWorkers`。因为RPC执行是同步的，不创建goroutine会导致select阻塞，不能响应其他channel可读的事件，另外goroutine中会写select监听的其他channel，不创建goroutine会导致死锁。

1. `doJobContextCh`可读：调用RPC的goroutine返回结果，执行重试策略
    * job执行成功：根据jobNumber判断是否是一个重试的job，如果是就从`failedJobNumber`中删除
    * job执行失败：把jobNumber添加到`failedJobNumber`，等待分发给空闲的worker重试

### 1.3 TODO：worker探死探活
1. 如果所有的job都已经分发，就不再向这个worker分发任务，这个空闲的worker就丢掉了，这里需要改进一下。
2. 当前的策略是RPC执行失败时就不再向master回收这个worker，假设worker服务部署在固定的机器上，不能因为一次RPC调用失败就把这个worker丢了，那么master需要维护所有worker的列表并对其探活，可以通过增加心跳实现，如果心跳失败说明worker已经死了，那么不再向这个worker分发job，当心跳恢复了再向worker分发job。因为当前模拟故障的方法是worker执行n次RPC请求退出，没有模拟worker退出以后用相同的地址重启，所以没实现这个逻辑。

## 3 mapreduce代码分析
### 3.1 MR执行逻辑
#### 3.1.1 `mapreduce.(*MapReduce).Split`
按照map任务数把输入文件分割成大小尽量相同（按行读取，当一个块累计读取长度超过输入文件大小/map任务数时，生成一个新块）的块
分割后文件名：mrtmp.${input_filename}.${map_job_number}，${map_job_number}的取值范围是[0, MapReduce.nMap)
#### 3.1.2 `mapreduce.(*MapReduce).DoMap`
1. 打开一个分割后的输入文件，读取文件内容到一个string中，执行map函数
2. map函数的返回值类型`[]mapreduce.KeyValue`，例：对于word count，key是word，value是这个word在当前分片中出现的次数
3. 遍历上面的slice，生成中间结果文件，按照`key%MapReduce.nReduce`把slice中的KeyValue写入到相应的中间结果文件
4. 中间结果文件的命名：mrtmp.${input_filename}.${map_job_number}.${reduce_job_number}，**对于一个map job，只读取一个分割后的输入文件，生成MapReduce.nReduce个中间结果文件**。
#### 3.1.3 `mapreduce.(*MapReduce).DoReduce`
1. 选择中间结果文件，假设reduce的jobNumber为3，nMap为10，那么读取的中间结果文件为mrtmp.${input_filename}.{0..9}.3
2. 读取中间结果文件生成map，key为map输出的key，value为map输出的value的list（同一个key可能分布在不同的分割后的输入文件中，所以value为list）
3. 按排序后的key遍历生成的map，将key和[]value作为参数传递到用户的Reduce函数中
4. 函数的返回值写入Reduce结果文件，文件名为：mrtmp.${input_filename}-res-${reduce_job_number}，一个reduce job生成一个结果文件
#### 3.1.4 `mapreduce.(*MapReduce).Merge`
对所有reduce job生成的结果文件，按照key做多路归并排序，输出一个最终结果文件：mrtmp.${input_filename}

### 3.2 框架
#### 3.2.1 `mapreduce.RunSingle`
单线程顺序执行map和reduce
#### 3.2.2 `mapreduce.(*MapReduce).Run`
多协/进程（单测中是用协程分别模拟master和worker，wc.go中是master和worker分别是两个进程）模拟master和worker
```
main/wc.go
// Can be run in 3 ways:
// 1) Sequential (e.g., go run wc.go master x.txt sequential)
// 2) Master (e.g., go run wc.go master x.txt localhost:7777)
// 3) Worker (e.g., go run wc.go worker localhost:7777 localhost:7778 &)
```

### 3.3 其他
1. 单测使用的是unix域socket，默认创建的路径是`/var/tmp`，如果对这个目录没权限，会执行失败

### 附

```go
func Map(value string) *list.List {
    m := make(map[string]int)
    f := func(c rune) bool {
        return !unicode.IsLetter(c)
    }
    for _, word := range strings.FieldsFunc(value, f) {
        m[word]++
    }

    l := list.New()
    for word, count := range m {
        l.PushBack(mapreduce.KeyValue{word, strconv.Itoa(count)})
    }
    return l
}

func Reduce(key string, values *list.List) string {
    nSum := 0
    for e := values.Front(); e != nil; e = e.Next() {
        if count, err := strconv.Atoi(e.Value.(string)); err == nil {
            nSum += count
        }
    }
    return strconv.Itoa(nSum)
}

// TestBasic
// func (mr *MapReduce) RunMaster() *list.List {
//  // Your code here
//  jobNumber := 0
//  nTotalJob := mr.nMap + mr.nReduce
//  for {
//      select {
//      case workerAddress := <-mr.registerChannel:
//          go func() {
//              mr.idleWorkers <- workerAddress
//          }()
//      case workerAddress := <-mr.idleWorkers:
//          if jobNumber == nTotalJob {
//              return mr.KillWorkers()
//          }
//          var jobArgs DoJobArgs
//          if jobNumber < mr.nMap {
//              jobArgs = DoJobArgs{mr.file, "Map", jobNumber, mr.nReduce}
//          } else {
//              jobArgs = DoJobArgs{mr.file, "Reduce", jobNumber - mr.nMap, mr.nMap}
//          }
//          jobNumber += 1
//          go func() {
//              var reply DoJobReply
//              call(workerAddress, "Worker.DoJob", jobArgs, &reply)
//              mr.idleWorkers <- workerAddress
//          }()
//      }
//  }
// }

// TestFailure
type DoJobContext struct {
    DoJobReply
    JobNumber int
}

func (mr *MapReduce) RunMaster() *list.List {
    // Your code here
    jobNumber := 0
    totalJobNumber := mr.nMap + mr.nReduce
    failedJobNumber := make(map[int]struct{}, 0)
    doJobContextCh := make(chan DoJobContext)
    runningJobCount := 0
    for {
        select {
        case workerAddress := <-mr.registerChannel:
            go func() {
                mr.idleWorkers <- workerAddress
            }()
        case workerAddress := <-mr.idleWorkers:
            if jobNumber >= totalJobNumber && runningJobCount == 0 && len(failedJobNumber) == 0 {
                return mr.KillWorkers()
            }

            var thisJobNumber int
            if len(failedJobNumber) == 0 {
                if jobNumber >= totalJobNumber {
                    continue
                }
                thisJobNumber = jobNumber
                jobNumber++
            } else {
                for number := range failedJobNumber {
                    thisJobNumber = number
                    delete(failedJobNumber, number)
                    break
                }
            }
            runningJobCount++

            var jobArgs DoJobArgs
            if thisJobNumber < mr.nMap {
                jobArgs = DoJobArgs{mr.file, "Map", thisJobNumber, mr.nReduce}
            } else {
                jobArgs = DoJobArgs{mr.file, "Reduce", thisJobNumber - mr.nMap, mr.nMap}
            }

            go func() {
                var reply DoJobReply
                ok := call(workerAddress, "Worker.DoJob", jobArgs, &reply)
                fmt.Printf("worker[%s] jobNumber[%d] operation[%s] ok[%v] reply[%v]\n", workerAddress, jobArgs.JobNumber, jobArgs.Operation, ok, reply.OK)

                doJobContext := DoJobContext{reply, jobArgs.JobNumber}
                if jobArgs.Operation == "Reduce" {
                    doJobContext.JobNumber += mr.nMap
                }
                doJobContextCh <- doJobContext
                if ok {
                    mr.idleWorkers <- workerAddress
                }
            }()
        case doJobContext := <-doJobContextCh:
            runningJobCount--
            if doJobContext.OK {
                if _, exists := failedJobNumber[doJobContext.JobNumber]; exists {
                    delete(failedJobNumber, doJobContext.JobNumber)
                }
            } else {
                failedJobNumber[doJobContext.JobNumber] = struct{}{}
            }
        }
    }
}
```
