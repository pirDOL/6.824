##第1讲：简介和实验综述

###6.824：分布式系统工程

什么是分布式系统？

* 许多通过网络协作的计算机。
* 例子：互联网电子邮件，Athena文件服务（AFS），Google MapReduce等。

为什么使用分布式？

* 连接物理隔离的实体（实体应该指的是计算机）。
* 通过物理隔离获得安全性。
* 通过对单点的冗余（replication）实现容错（fault-tolerant）。
* 通过并行的CPU、内存、磁盘、网络提高性能。

但是：

* 复杂，难以调试。
* 出现了一类新的问题，比如部分失效。
* 建议：如果集中式系统能够工作就不要用分布式。

为什么上这门课：

* 有趣：困难的问题，不明显的解决方法。
* 时下活跃的研究领域：研究取得了很多进展，但是也有更大的未解决的问题。
* 真实工程中应用：大型网站的发展所驱动。
* 可以亲自实践（hands-on）：可以在实验中构建真实的分布式系统。

###[课程内容](http://pdos.csail.mit.edu/6.824)

* 课上会对伟大的想法、论文、实验进行介绍。
* 阅读：论文作为研究的案例。
1. 请在课前阅读论文，否则上课会很枯燥，你不可能通过上课听就毫不费力的学会（pick it up by listening）。
2. 每篇论文都有一个你要回答的问题，并且你需要提一个你想要了解的问题，在课前提交问题和答案，篇幅为一到两段文字。

* 期中考试和期末考试。
* 实验：逐步构建复杂、带有容错性的服务。
1. 第一次实验截止到周一。
2. 博士同学可以将第五次实验替换成一个小的研究项目，请和我们讨论。
* 助教：会回答关于讲义中的问题，帮助你们解决实验中的问题，在工作时间可以找到他们。

###主要的话题

例子：一个共享文件系统，用户可以协作，就像AFS那样。有很多客户端计算机使用它的服务。

####话题：架构

* 接口是什么？
1. 客户端和服务器对话，它们说什么？
2. 文件系统（文件、文件名、目录等）如何实现？
3. 磁盘块和文件系统位于客户端？
4. 独立的文件命名服务器+文件服务器？
5. 独立的文件服务器+磁盘块服务器？

* 单个机房还是统一的大范围系统？
后者更难。

* 透明性
它用起来要像本地磁盘上的文件系统那样吗？还是客户端需要知道服务端分布式结构（比如客户端需要知道文件的服务器路由或者处理错误）。

* C/S还是P2P？
所有上面这些问题都影响到性能、可用性、容错性。

####话题：实现

* 如何简化网络通信？
网络通信会很麻烦，比如信息的格式化、重传、主机名等等。框架会帮助解决这些麻烦，比如RPC、MapReduce等。

* 如何处理固有的并发性？
线程和锁。

####话题：性能
* 分布式的弊端
1. 网络读写、传输延时会造成额外的开销，从而带来性能瓶颈。
2. 分布式会有很多坑，比如缓存、一致性、预取（pre-fetch）。

* 分布式的好处
并发、客户端可以就近选择服务器。

* 想法：可伸缩设计。
服务器数量乘以N，性能也会增加N倍。

* 需要一种方法把负载平均分配到N台机器上。
1. 把数据分散到许多服务器上根据文件名的hash值或者直接由用户决定。
2. Move files around dynamically to even out load?
3. "Stripe" each file's blocks over the servers?
    
* 性能的伸缩很少有完美的情况（即服务器数量加倍，性能不变）
1. 有些操作（比如文件查找）是全局的，需要处理所有的服务器。
2. 负载不均衡，所有客户端都想要获得一个文件，存储这个文件的服务器使用率是100%，其他新增加的服务器是空闲的。

####话题：容错性
* 大型系统（1000台服务器、复杂的网络）经常会有一些东西出故障。    
* 我们需要的是：
1. 可用性：尽管错误发生了，系统仍然可用，具体表现在文件还能访问。
2. 持久性：文件在某一天还会恢复。
* 可用性的想法：冗余。
1. 服务器构成机器对，每个文件在一对机器上同时存储。
2. 客户端把操作请求发送到两个服务器。
3. 如果一个服务器宕机了，客户端能够使用另一个。
* 提问（opportunity）：operate from both "replicas" independently if partitioned?
* 提问：2个服务器能够获得2倍的可用性和2倍的性能吗？（故障率是原来的平方，性能至少不会增加。）

####话题：一致性
* 假定用户和服务器制定了操作的含义，比如读操作返回最近被写的值。
* 一致性的目的就是实现这个约定，不论是否出现错误、冗余、缓存、并发等等。
* 问题：保持冗余是同一性的。
1. 如果一台机器宕机了，它会错过一些客户端的操作，重启后必须更新内容。
2. 如果网络有故障，服务器是好的，从而保存一份数据的两台服务器看到了不同的操作。比如冗余服务器只能看到删除文件的操作，这样冗余服务器上的文件会被一点点的删除完毕，造成的结果就是集群分裂（split brain）。
* 问题：客户端看到更新的顺序可能不同，其原因是缓存或者冗余。
我把6.824目录设置为私有的，然后助教创建了年级文件。那么如果另一个冗余上面，这两个操作执行的顺序反了会怎么样？
* 一致性会导致性能的恶化，因为通信和阻塞。
许多系统会走捷径（cut corners），降低对一致性的约束或者是把数据不一致的负担转移到应用程序。

###实验

* 目标：容错性和一致性（分布式系统的核心问题）
1. 实验1：MapReduce
2. 实验2~5：存储服务器。通过容忍更多种类的错误渐进复杂。模型源自于真实的系统，例如MongoDB。成果是一个真实世界中能够使用的1000台服务器的核心设计。

* 能从实验中学到什么
1. 上课听讲、阅读论文很容易让你觉得自己懂了，但是实验会强迫你真的懂了。
2. 你需要自己做一些设计，我们提供框架、需求和测试案例，你不得不竭尽所能解决问题。
3. 你会积累调试分布式系统的经验，比如处理并发、不可靠的消息。

* 我们尝试确保较困难的问题都是和分布式系统有关的，不会涉及编程语言、程序库等，并且Go语言提供了类型安全、垃圾回收、灵活的RPC库，另外实验所要实现的服务都很简单，比如MapReduce、key/value存储。
* 分数取决于你通过的测试案例数，测试案例我们已经提供给你。注意：如果你的程序通常会成功运行，但是偶尔会失败，chances are it will fail when we run it。

* 代码评审
阅读其他人的实验代码，可能会学到其他的方法，对其他人的解答提出反馈，你也可以获得其他人的反馈。

####实验1：MapReduce
* 并行编程的框架，运行在1000台计算机上。
* 帮助你熟悉Go语言以及分布式编程。
* 首先暴露一些错误，然后在后面的实验中可以激励你实现更好的容错性。
* 流行的分布式编程框架，有很多优秀的衍生实现（with many intellectual children）。

#####MapReduce计算模型
1. 程序员定义Map和Reduce函数。
2. 输入是一些key/value对，首先划分为若干个分片。例如：输入是文件，key/value对就是文件名/内容。
3. MapReduce在每个分片上调用Map函数，输出一个key2/value2的集合，例如：第一个分片输出的是a,1 b,7 c,9。
4. MapReduce收集Map函数输出的所有key2/value2，把key2相同的value2的合并，把key2/list(value2)传递到Reduce函数。
5. Reduce函数输出key3/value3的集合就是最终输出。
```
Input Map -> a,1 b,7 c,9
Input Map ->     b,2 
Input Map -> a,3     c,7
             |   |   |
             |   |   -> Reduce -> c,16
             |   -----> Reduce -> b,9
             ---------> Reduce -> a,4
```

#####例：单词计数
* 输入：成千上万的文本文件。
```    
Map(filename, content)
    split content into words
    for each word w
          emit(w, "1")
Reduce(k, v)
    emit(len(v))
```

* MapReduce在单词计数中做了什么？
1. 输入文件
```
f1: a b
f2: b c
```
2. 把"f1"发送给map worker 1
```
Map("f1", "a b") -> <a 1> <b 1>
```
3. 把"f2"发送给map worker 2
```
Map("f2", "b c") -> <b 1> <c 1>
```
4. 框架等待直到两个Map任务完成。
5. worker对Map的输出按照key排序，然后框架告诉每个reduce worker它们reduce哪个key。
6. 每个reduce worker在知道了自己的key以后，从相应的map worker拉取结果。
```
reduce worker 1: key a
map worker 1 -> <a 1>

reduce worker 2: key b c
map worker 1 -> <b 1>
map worker 2 -> <b 1> <c 1>
```
7. reduce worker在拉取的结果上调用Reduce函数。
```
reduce worker 1: Reduce("a", [1]) -> 1
reduce worker 2: Reduce("b", [1 1]) -> 2
                 Reduce("c", [1]) -> 1
```

* 为什么MapReduce框架很方便：
1. 程序员只需要考虑核心工作即Map函数和Reduce函数，不需要考虑网络通信和错误处理。
2. 对Map函数的中间结果汇总再发送给Reduce函数满足很多应用场景，例如单词统计。
3. 有些应用场景并不适用，因为MapReduce只允许在Map和Reduce之间按照一种类型的通信。例如统计单词同时按照频率排序。

* 为什么MapReduce可能拥有良好的性能：
1. Map函数和Reduce函数可以在不同的worker上并发运行。worker数量增加N倍，运行时间就降低N倍。
2. 但是现实没有理论计算那么好：移动Map函数的输出到reduce worker，掉队的worker，读写网络文件系统。

* 故障呢：
1. MapReduce使用时有上千个worker，输入数据量巨大。假如每个worker每年宕机一次，1000个worker中每天都会有三个宕机的。所以一个规模很大的MapReduce任务会深受worker故障之苦。
2. 还有一些其他的错误：worker运行的很慢、CPU计算错误、master宕机、网络丢包、MapReduce程序库以及Map和Reduce函数软件中的bug。

* 处理错误的工具（MapReduce使用了下面所有的方法）：
1. 重试：如果worker故障，重新在另一个worker上面运行。
2. 冗余：Map和Reduce都同时在两个worker上运行。
3. 替代：为了长期的健康。

* 关于重试方法的思考题：
1. 如何知道什么时候重试？
能不能检测Map或者Reduce worker是否崩溃？
能不能检测worker的错误输出？
能不能区分worker故障和网络故障？（can we distinguish worker failure from worker up, network lossy?）
2. 为什么重试是正确的？
如果Map产生了一些输出，然后崩溃了怎么办， 我们会得到重复的输出吗？
要是同一个Map执行了两次怎么办？
通常调用一个函数两次和调用它一次是不同的，为什么对于Map和Reduce函数是可以的？

* 对上面的疑惑有帮助的假设：必须做一些假设，否则上面的问题太难了。
1. 软件中没有bug。
2. 没有不正确的输出：worker要么输出正确的结果，要么什么也不输出。即假定出现错误就停止。
3. master不会崩溃。
4. Map和Reduce都只依赖于它们的参数，不会读取文件、不会互相交谈、不会收发网络消息等等。

#####实验1有三部分：
1. I：单词计数的Map函数和Reduce函数。
2. II：我们给你一个分布式多服务器的框架中的大部分，请填写代码完成任务分发工作。
3. III：通过重试实现master处理worker崩溃。

* I：main/wc.go
1. 填写Map和Reduce的存根[stub](https://en.wikipedia.org/wiki/Stub_(distributed_computing)它们实现单词统计
2. Map的参数是string，内容是一大块输入文件。
注：stub是用于转换参数的代码，客户端调用RPC时通过stub实现参数序列化（marshal）并把服务器返回的结果反序列化（unmarshal），服务器端stub执行过程相反。

* Part I参考答案的demo
```  
  ./wc master kjv12.txt sequential
  more mrtmp.kjv12.txt-1-2
  more mrtmp.kjv12.txt
```

* Part I：顺序框架：mapreduce/mapreduce.go文件中的RunSingle()函数
包括split、maps、reduces、merge

* Part II：并行框架
master、workers、共享文件系统
1. 我们的代码会在调用你写的master代码之前分割输入，会在你的master代码返回之后合并输出。
2. 我们的代码只告诉master map和reduce分片的数量。
3. 每个worker向master发送注册RPC，你的master代码必须维护一个已注册的worker列表。
4. master发送DoJob RPC给worker，如果有10个map任务、3个worker，开始一下子发送3个任务，等待直到有一个worker任务完成并返回，然后发送新任务给它，直到10个任务都完成，reduce同理。
5. master只需要发送任务的序号以及是map还是reduce给worker，worker会从文件读取输入。
6. master代码只需要知道map任务和reduce任务的数量，保存在名字为mr的参数中。

#####周四：
1. master和worker通过RPC通信，从而隐藏了网络的复杂性。
2. 更多的关于RPC的知识。